# My Reading List
A repo devoted to publicly available resources on machine learning that acts as my reading list.

# Papers

[Henderson, P., Li, X., Jurafsky, D., Hashimoto, T., Lemley, M., Liang P. (2023). Foundation Models and Fair Use. *arXiv e-prints*](https://arxiv.org/pdf/2303.15715.pdf)

[Taori, R., Hashimoto, T.B. (2022). Data Feedback Loops: Model-driven Amplification of Dataset Biases. *arXiv e-prints*](https://arxiv.org/pdf/2209.03942.pdf)

[Henderson, P., Li, X., Jurafsky, D., Hashimoto, T., Lemley. P.A., Liang, P. Whose Opinions Do Language Models Reflect? (2022).  *arXiv e-prints*](https://arxiv.org/pdf/2303.17548.pdf)

[Zhang, M., Press, O., Merrill, W., Liu, A., Smith, N.A. How Language Model Hallucinations Can Snowball (2023).  *arXiv e-prints*](https://arxiv.org/pdf/2305.13534.pdf)

[Bender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? (2021). ACM Facct](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922)


# Tutorials

[Liang,  P., Morency L.P. (2023). *ICML Tutorial: Multimodal Machine Learning: Principles, Challenges, and Open Questions*](https://icml.cc/virtual/2023/tutorial/21551) [(Slides, Materials, Etc.)](https://cmu-multicomp-lab.github.io/mmml-tutorial/icml2023/)

# Postings

[Sampath, S. (2023). *The Animated Transformer*](https://prvnsmpth.github.io/animated-transformer/)https://prvnsmpth.github.io/animated-transformer/)


